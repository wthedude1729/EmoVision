{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyP+0biyiD8oil4hiJOHzuBW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"_8d7A8ttNYm8"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FL3i15XR4ZT2","executionInfo":{"status":"ok","timestamp":1722293564234,"user_tz":420,"elapsed":36663,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"outputId":"96bed949-d013-4d7e-de1a-f888de028ad9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Data manipulation and analysis\n","import pandas as pd\n","import numpy as np\n","\n","# Data visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Machine learning\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Deep learning with TensorFlow\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n","from tensorflow.keras.utils import to_categorical\n","\n","# Deep learning with PyTorch\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torchvision import models\n","from torchvision.models import resnet50, ResNet50_Weights\n","from torchvision.models import resnet18, ResNet18_Weights\n","\n","# Natural Language Processing (NLP)\n","import nltk\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","\n","# Miscellaneous\n","import os\n","import re\n","import time\n","import pickle\n","from PIL import Image\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","source":["# Data Import"],"metadata":{"id":"lj5LPvLSMXgo"}},{"cell_type":"code","source":["nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","b_size = 10\n","\n","data = torch.load(\"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/ekman.pt\")\n","train_length = (int)(0.9 * len(data))\n","train_set, val_set = torch.utils.data.random_split(data, [train_length, len(data) - train_length])\n","\n","train_loader = DataLoader(train_set, batch_size = b_size, shuffle = True, pin_memory = True, num_workers = 2)\n","test_loader = DataLoader(val_set, batch_size = b_size, shuffle = False, pin_memory = True, num_workers = 2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GJpIBLgy4gKy","executionInfo":{"status":"ok","timestamp":1722293568292,"user_tz":420,"elapsed":4063,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"outputId":"e6b4d3ff-5655-4455-c42e-a8d6869a70a9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["import os.path\n","\n","frame_process = transforms.Compose([\n","    transforms.Resize((32, 32)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n","])\n","\n","def crop(image):\n","  return image.crop((80, 58, 577, 428))\n","\n","spect_process = transforms.Compose([\n","    transforms.Lambda(crop),\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","frame_directory = \"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/ekman6_split/\"\n","spect_directory = \"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/ekman6_spectro/\"\n","folders = [\"anger/\", \"disgust/\", \"fear/\", \"joy/\", \"sadness/\", \"surprise/\"]\n","df = pd.read_csv(\"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/ekman6_texts/en_transcripts.csv\")\n","\n","def preprocess_text(text: str) -> str:\n","    # remove links\n","    text = re.sub(r\"http\\S+\", \"\", text)\n","    # remove special chars and numbers\n","    text = re.sub(\"[^A-Za-z]+\", \" \", text)\n","    # remove stopwords\n","    # 1. tokenize\n","    tokens = nltk.word_tokenize(text)\n","    # 2. check if stopword\n","    tokens = [w.lower() for w in tokens if not w in stopwords.words(\"english\")]\n","    return tokens\n","\n","def get_frame_tensor(i):\n","  frames = []\n","  last_valid_filename = \"\"\n","  for j in range(1, 30):\n","    filename = str(i) + \"_\" + str(j) + \".jpg\"\n","    if not os.path.isfile(frame_directory + folders[(int)(i/50)] + filename):\n","      filename = last_valid_filename\n","    if filename == \"\":\n","      print(str(i) + \"_\" + str(j) + \".jpg\")\n","    file = Image.open(frame_directory + folders[(int)(i/50)] + filename)\n","    file = frame_process(file)\n","    frames.append(file)\n","    last_valid_filename = filename\n","  frames = torch.stack(frames)\n","  return frames\n","\n","def get_spect_tensor(i):\n","  filename = str(i) + \".jpg\"\n","  file = Image.open(spect_directory + folders[(int)(i/50)] + filename)\n","  file = spect_process(file)\n","  return file\n","\n","dictionary = {\n","    'EMPTY': 1 # EMPTY --> signal that the text is empty and contains nothing\n","}\n","\n","def get_text_tensor(i):\n","  text = df.columns[i]\n","  text = preprocess_text(text)\n","  liszt = [] # the processed version of the text\n","  for i in range(len(text)):\n","    if text[i] in dictionary:\n","      liszt.append((int)(dictionary[text[i]]))\n","    else:\n","      size = len(dictionary) + 1\n","      dictionary[text[i]] = size\n","      liszt.append((int)(dictionary[text[i]]))\n","  return torch.Tensor(liszt).to(device).to(torch.int64), len(text)\n"],"metadata":{"id":"aKkLhpG04hWq","executionInfo":{"status":"ok","timestamp":1722293568965,"user_tz":420,"elapsed":674,"user":{"displayName":"William W.","userId":"17998644639780254164"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["text_tensors = []\n","text_lengths = []\n","MXLEN = 0\n","\n","num_input_videos = 300\n","\n","for i in range(num_input_videos):\n","  tt, text_length = get_text_tensor(i)\n","  text_tensors.append(tt)\n","  text_lengths.append(text_length)\n","  MXLEN = max(MXLEN, (int)(tt.size(0)))\n","\n","text_tensors = torch.nn.utils.rnn.pad_sequence(text_tensors, batch_first = True)"],"metadata":{"id":"pv-qW14p4ix8","executionInfo":{"status":"ok","timestamp":1722293575144,"user_tz":420,"elapsed":6181,"user":{"displayName":"William W.","userId":"17998644639780254164"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#frame_tensors = []\n","spect_tensors = []\n","\n","for i in range(300):\n","  #frame_tensors.append(get_frame_tensor(i))\n","  spect_tensors.append(get_spect_tensor(i))"],"metadata":{"id":"DELWdT8Z4kHp","executionInfo":{"status":"ok","timestamp":1722293770392,"user_tz":420,"elapsed":195249,"user":{"displayName":"William W.","userId":"17998644639780254164"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Models"],"metadata":{"id":"yNhJ2SFliG0N"}},{"cell_type":"code","source":["class LSTM_Classifier(nn.Module):\n","  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n","    super(LSTM_Classifier, self).__init__()\n","    # Embedding layer converts integer sequences to vector sequences\n","    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","    # LSTM layer process the vector sequences\n","    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers = n_layers, bidirectional = bidirectional, dropout = dropout, batch_first = True)\n","    #                     input           output                             bisexual?                      dropout_prob      whether or not batch_size comes first in the tensor.size()\n","    # Dense layer to predict\n","    self.fc = nn.Linear(hidden_dim * (2 if bidirectional == True else 1), output_dim)\n","    # Prediction activation function\n","    self.sigmoid = nn.Sigmoid()\n","\n","  def forward(self, text, text_lengths):\n","    embedded = self.embedding(text) # embedded version\n","    # Thanks to packing, LSTM don't see padding tokens\n","    # and this makes our model better\n","    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, batch_first=True, enforce_sorted = False)\n","    packed_output, (hidden_state, cell_state) = self.lstm(packed_embedded)\n","    # Concatenating the final forward and backward hidden states\n","    hidden = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1)\n","    dense_outputs = self.fc(hidden)\n","    #Final activation function\n","    dense_outputs = nn.functional.relu(dense_outputs)\n","    return dense_outputs"],"metadata":{"id":"wEDih119iJHJ","executionInfo":{"status":"ok","timestamp":1722293770393,"user_tz":420,"elapsed":9,"user":{"displayName":"William W.","userId":"17998644639780254164"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class Smash(nn.Module):\n","  def __init__(self):\n","    super(Smash, self).__init__()\n","    self.fcnn = nn.Sequential(\n","      nn.Linear(12, 12),\n","      nn.ReLU(),\n","      nn.Linear(12, 6)\n","    )\n","    self.bilstm = LSTM_Classifier(vocab_size = len(dictionary) + 1,\n","                         embedding_dim = 100,\n","                         hidden_dim = 64,\n","                         output_dim = 6,\n","                         n_layers = 5,\n","                         bidirectional = True,\n","                         dropout = 0.5).to(device)\n","    self.resn = resnet18(num_classes = 6)\n","\n","  def forward(self, x1, x2, tlengths):\n","    x1 = self.resn(x1)\n","    x2 = self.bilstm(x2, tlengths)\n","    x1 = torch.cat((x1, x2), dim = -1)\n","    x1 = self.fcnn(x1)\n","    return x1"],"metadata":{"id":"qZVERsrAiMOk","executionInfo":{"status":"ok","timestamp":1722293770393,"user_tz":420,"elapsed":6,"user":{"displayName":"William W.","userId":"17998644639780254164"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Training Loop"],"metadata":{"id":"0P_fkls6NcLJ"}},{"cell_type":"code","source":["model = Smash().to(device)\n","\n","epochs = 15\n","optimizer = optim.Adam(model.parameters(), lr = 0.0005)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","tl = []\n","\n","for i in range(epochs):\n","  model.train()\n","  train_loss = 0.00\n","  correct = 0.00\n","  total = 0.00\n","  for indices, label in train_loader:\n","    indices = indices.cuda()\n","    label = label.cuda()\n","\n","    # getting the text for the index-th video\n","    text_batch = []\n","    for index in indices:\n","      text = text_tensors[index].to(device)\n","      # if the text ends up being nothing\n","      if text_lengths[index] == 0:\n","        text[0] = dictionary['EMPTY']\n","        # dimensionality voodoo\n","        text_lengths[index] = 1\n","      text_batch.append(text)\n","    text_batch = torch.stack(text_batch)\n","    text_batch = text_batch.squeeze(1)\n","\n","    # getting the spectrograms\n","    spect_batch = []\n","    for index in indices:\n","      spect = spect_tensors[index].to(device)\n","      spect.requires_grad = True\n","      spect_batch.append(spect)\n","    spect_batch = torch.stack(spect_batch)\n","\n","    # getting the text lengths\n","    textl = []\n","    for index in indices:\n","      textl.append(text_lengths[index])\n","\n","    # zero-ing gradients\n","    optimizer.zero_grad()\n","\n","    # output of the final NN on the super-tensor\n","    y_pred = model(spect_batch, text_batch, textl).to(device)\n","\n","    # creating one-hot vector for the label for the index-th video\n","    labels = torch.full((b_size, 6,), 0.00).cuda()\n","    for j in range(b_size):\n","      labels[j][label[j]] = 1.00\n","\n","    # computing the Cross Entropy Loss and backpropagating\n","    loss = loss_fn(y_pred, labels)\n","    loss.backward()\n","\n","    # updating gradients\n","    optimizer.step()\n","\n","    # statistics\n","    train_loss += loss.item()/len(train_loader)\n","    prediction = y_pred.argmax(dim=1)\n","    label = label.squeeze(1)\n","    correct += (prediction.eq(label).sum()).item()\n","    total += label.size(0)\n","\n","  print(correct, total)\n","  # more statistics\n","  tl.append(train_loss)\n","  print(f\"Epoch: {i+1}/{epochs}, Training Loss: {train_loss:.4f}, Training Accuracy: {correct/total:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQYekX8U4lhP","executionInfo":{"status":"ok","timestamp":1722293826761,"user_tz":420,"elapsed":56374,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"outputId":"71b7a87d-818d-4d1c-8633-ddf62ac99bc7"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["41.0 270.0\n","Epoch: 1/15, Training Loss: 1.8178, Training Accuracy: 0.1519\n","47.0 270.0\n","Epoch: 2/15, Training Loss: 1.7974, Training Accuracy: 0.1741\n","46.0 270.0\n","Epoch: 3/15, Training Loss: 1.7980, Training Accuracy: 0.1704\n","46.0 270.0\n","Epoch: 4/15, Training Loss: 1.7979, Training Accuracy: 0.1704\n","46.0 270.0\n","Epoch: 5/15, Training Loss: 1.7976, Training Accuracy: 0.1704\n","46.0 270.0\n","Epoch: 6/15, Training Loss: 1.7973, Training Accuracy: 0.1704\n","46.0 270.0\n","Epoch: 7/15, Training Loss: 1.7971, Training Accuracy: 0.1704\n","46.0 270.0\n","Epoch: 8/15, Training Loss: 1.7968, Training Accuracy: 0.1704\n","46.0 270.0\n","Epoch: 9/15, Training Loss: 1.7967, Training Accuracy: 0.1704\n","46.0 270.0\n","Epoch: 10/15, Training Loss: 1.7964, Training Accuracy: 0.1704\n","46.0 270.0\n","Epoch: 11/15, Training Loss: 1.7962, Training Accuracy: 0.1704\n","46.0 270.0\n","Epoch: 12/15, Training Loss: 1.7960, Training Accuracy: 0.1704\n","46.0 270.0\n","Epoch: 13/15, Training Loss: 1.7959, Training Accuracy: 0.1704\n","46.0 270.0\n","Epoch: 14/15, Training Loss: 1.7956, Training Accuracy: 0.1704\n","46.0 270.0\n","Epoch: 15/15, Training Loss: 1.7954, Training Accuracy: 0.1704\n"]}]},{"cell_type":"markdown","source":["# Validation Loop"],"metadata":{"id":"3Z5c39Xaqe4Z"}},{"cell_type":"code","source":["model.eval()\n","\n","for indices, label in train_loader:\n","    indices = indices.cuda()\n","    label = label.cuda()\n","\n","    # getting the text for the index-th video\n","    text_batch = []\n","    for index in indices:\n","      text = text_tensors[index].to(device)\n","      # if the text ends up being nothing\n","      if text_lengths[index] == 0:\n","        text[0] = dictionary['EMPTY']\n","        # dimensionality voodoo\n","        text_lengths[index] = 1\n","      text_batch.append(text)\n","    text_batch = torch.stack(text_batch)\n","    text_batch = text_batch.squeeze(1)\n","\n","    # getting the spectrograms\n","    spect_batch = []\n","    for index in indices:\n","      spect = spect_tensors[index].to(device)\n","      spect.requires_grad = True\n","      spect_batch.append(spect)\n","    spect_batch = torch.stack(spect_batch)\n","\n","    # getting the text lengths\n","    textl = []\n","    for index in indices:\n","      textl.append(text_lengths[index])\n","\n","    # output of the final NN on the super-tensor\n","    with torch.no_grad():\n","      y_pred = model(spect_batch, text_batch, textl).to(device)\n","\n","    # creating one-hot vector for the label for the index-th video\n","    labels = torch.full((b_size, 6,), 0.00).cuda()\n","    for j in range(b_size):\n","      labels[j][label[j]] = 1.00\n","\n","    train_loss += loss.item()/len(train_loader)\n","    prediction = y_pred.argmax(dim=1)\n","    label = label.squeeze(1)\n","    correct += (prediction.eq(label).sum()).item()\n","    total += label.size(0)\n","\n","print(f\"Validation Accuracy: {correct/total:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7kfE-QeCqhQv","executionInfo":{"status":"ok","timestamp":1722293828099,"user_tz":420,"elapsed":1342,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"outputId":"a2aaa74e-d0cb-40bd-b5ed-c794c6f02e21"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Accuracy: 0.1704\n"]}]}]}