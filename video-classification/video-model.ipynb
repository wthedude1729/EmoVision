{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNFqRaDe75jTUfuKNuWUJ7h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"vKDPUAqBXkoF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dlzxaqpNJx5i"},"outputs":[],"source":["# Data manipulation and analysis\n","import pandas as pd\n","import numpy as np\n","\n","# Data visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Machine learning\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Deep learning with TensorFlow\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n","from tensorflow.keras.utils import to_categorical\n","\n","# Deep learning with PyTorch\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torchvision import models\n","from torchvision.models import resnet50, ResNet50_Weights\n","from torchvision.models import resnet18, ResNet18_Weights\n","\n","# Natural Language Processing (NLP)\n","import nltk\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","\n","# Miscellaneous\n","import os\n","import re\n","import time\n","import pickle\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"8nFTwS-RXmVk"}},{"cell_type":"markdown","source":["3D CNN"],"metadata":{"id":"RACeNj3rX6EB"}},{"cell_type":"code","source":["class CNN3d(nn.Module):\n","  def __init__(self):\n","\n","\n","  def forward(self, x):\n"],"metadata":{"id":"OLlzNJ7IXoQX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["LSTM"],"metadata":{"id":"btgzfDGdYBM-"}},{"cell_type":"code","source":["class LSTM_Classifier(nn.Module):\n","  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n","    super(LSTM_Classifier, self).__init__()\n","    # Embedding layer converts integer sequences to vector sequences\n","    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","    # LSTM layer process the vector sequences\n","    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers = n_layers, bidirectional = bidirectional, dropout = dropout, batch_first = True)\n","    #                     input           output                             bisexual?                      dropout_prob      whether or not batch_size comes first in the tensor.size()\n","    # Dense layer to predict\n","    self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","    # Prediction activation function\n","    self.sigmoid = nn.Sigmoid()\n","\n","  def forward(self, text, text_lengths):\n","    embedded = self.embedding(text) # embedded version\n","    # Thanks to packing, LSTM don't see padding tokens\n","    # and this makes our model better\n","    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, batch_first=True, enforce_sorted = False)\n","    packed_output, (hidden_state, cell_state) = self.lstm(packed_embedded)\n","    # Concatenating the final forward and backward hidden states\n","    hidden = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1)\n","    dense_outputs = self.fc(hidden)\n","    #Final activation function\n","    outputs = self.sigmoid(dense_outputs)\n","    return outputs"],"metadata":{"id":"GOkG_HkjX9QX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["FC NN"],"metadata":{"id":"HKhAhcfTYRbp"}},{"cell_type":"code","source":["fcnn = nn.Sequential(\n","    nn.Linear(18, 12),\n","    nn.Linear(12, 6),\n","    nn.Sigmoid()\n",")"],"metadata":{"id":"WDvSx7MxYR_-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Full Model (cross your fingers that this doesn't take forever to train)"],"metadata":{"id":"qycxOGoPYG1f"}},{"cell_type":"code","source":["model1 = CNN3d()\n","model2 = resnet18(pretrained = True) # output == 1000 neurons\n","model3 = LSTM_Classifier()\n","\n","epochs = 10\n"],"metadata":{"id":"W0FN8r02YItL"},"execution_count":null,"outputs":[]}]}