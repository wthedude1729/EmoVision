{"cells":[{"cell_type":"markdown","metadata":{"id":"vKDPUAqBXkoF"},"source":["# Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39486,"status":"ok","timestamp":1722273514510,"user":{"displayName":"William W.","userId":"17998644639780254164"},"user_tz":420},"id":"dlzxaqpNJx5i","outputId":"5c2c03bc-aedc-4cc7-ccd7-d356e92b7f53"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Data manipulation and analysis\n","import pandas as pd\n","import numpy as np\n","\n","# Data visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Machine learning\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Deep learning with TensorFlow\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n","from tensorflow.keras.utils import to_categorical\n","\n","# Deep learning with PyTorch\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torchvision import models\n","from torchvision.models import resnet50, ResNet50_Weights\n","from torchvision.models import resnet18, ResNet18_Weights\n","\n","# Natural Language Processing (NLP)\n","import nltk\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","\n","# Miscellaneous\n","import os\n","import re\n","import time\n","import pickle\n","from PIL import Image\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"8nFTwS-RXmVk"},"source":["# Models"]},{"cell_type":"markdown","metadata":{"id":"RACeNj3rX6EB"},"source":["3D CNN"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1722273514511,"user":{"displayName":"William W.","userId":"17998644639780254164"},"user_tz":420},"id":"OLlzNJ7IXoQX"},"outputs":[],"source":["class CNN3d(nn.Module):\n","  def __init__(self):\n","    super(CNN3d, self).__init__()\n","    self.c1 = nn.Conv3d(3, 6, kernel_size = 4, padding = 1, stride = 2)\n","    self.c2 = nn.Conv3d(6, 16, kernel_size = 10, padding = 0, stride = 2)\n","    # 16 x 3 x 4 x 4 = 256\n","    self.flatten = nn.Flatten()\n","    self.fc = nn.Sequential(\n","      nn.Linear(16 * 3 * 4 * 4, 128),\n","      nn.Linear(128, 64),\n","      nn.Linear(64, 6),\n","      nn.Softmax()\n","    )\n","\n","  def forward(self, x):\n","    x = self.c1(x)\n","    x = self.c2(x)\n","    x = nn.functional.relu(x)\n","    x = self.flatten(x)\n","    x = self.fc(x)\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"btgzfDGdYBM-"},"source":["LSTM"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1722273514511,"user":{"displayName":"William W.","userId":"17998644639780254164"},"user_tz":420},"id":"GOkG_HkjX9QX"},"outputs":[],"source":["class LSTM_Classifier(nn.Module):\n","  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n","    super(LSTM_Classifier, self).__init__()\n","    # Embedding layer converts integer sequences to vector sequences\n","    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","    # LSTM layer process the vector sequences\n","    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers = n_layers, bidirectional = bidirectional, dropout = dropout, batch_first = True)\n","    #                     input           output                             bisexual?                      dropout_prob      whether or not batch_size comes first in the tensor.size()\n","    # Dense layer to predict\n","    self.fc = nn.Linear(hidden_dim * (2 if bidirectional == True else 1), output_dim)\n","    # Prediction activation function\n","\n","  def forward(self, text, text_lengths):\n","    embedded = self.embedding(text) # embedded version\n","    # Thanks to packing, LSTM don't see padding tokens\n","    # and this makes our model better\n","    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, batch_first=True, enforce_sorted = False)\n","    packed_output, (hidden_state, cell_state) = self.lstm(packed_embedded)\n","    # Concatenating the final forward and backward hidden states\n","    hidden = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1)\n","    dense_outputs = self.fc(hidden)\n","    #Final activation function\n","    return dense_outputs"]},{"cell_type":"markdown","metadata":{"id":"HKhAhcfTYRbp"},"source":["FC NN"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1722273514511,"user":{"displayName":"William W.","userId":"17998644639780254164"},"user_tz":420},"id":"WDvSx7MxYR_-"},"outputs":[],"source":["class Smash(nn.Module):\n","  def __init__(self):\n","    super(Smash, self).__init__()\n","    self.fcnn = nn.Sequential(\n","      nn.Linear(10012, 12),\n","      nn.Linear(12, 6),\n","      nn.Softmax()\n","    )\n","\n","  def forward(self, x):\n","    x = self.fcnn(x)\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"hBbC7DiRixqL"},"source":["# Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4706,"status":"ok","timestamp":1722273519213,"user":{"displayName":"William W.","userId":"17998644639780254164"},"user_tz":420},"id":"mPGwHeaLirWh","outputId":"0804762a-9889-42f8-a7e2-46a844f66499"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","data = torch.load(\"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/ekman.pt\")\n","train_length = (int)(0.9 * len(data))\n","train_set, val_set = torch.utils.data.random_split(data, [train_length, len(data) - train_length])\n","\n","train_loader = DataLoader(train_set, shuffle = True, pin_memory = True, num_workers = 2)\n","test_loader = DataLoader(val_set, shuffle = False, pin_memory = True, num_workers = 2)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1958,"status":"ok","timestamp":1722273521157,"user":{"displayName":"William W.","userId":"17998644639780254164"},"user_tz":420},"id":"9ksNODHAkBOY"},"outputs":[],"source":["import os.path\n","\n","frame_process = transforms.Compose([\n","    transforms.Resize((32, 32)),\n","    transforms.ToTensor()\n","])\n","\n","def crop(image):\n","  return image.crop((80, 58, 577, 428))\n","\n","spect_process = transforms.Compose([\n","    transforms.Lambda(crop),\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","frame_directory = \"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/ekman6_split/\"\n","spect_directory = \"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/ekman6_spectro/\"\n","folders = [\"anger/\", \"disgust/\", \"fear/\", \"joy/\", \"sadness/\", \"surprise/\"]\n","df = pd.read_csv(\"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/ekman6_texts/en_transcripts.csv\")\n","\n","def preprocess_text(text: str) -> str:\n","    # remove links\n","    text = re.sub(r\"http\\S+\", \"\", text)\n","    # remove special chars and numbers\n","    text = re.sub(\"[^A-Za-z]+\", \" \", text)\n","    # remove stopwords\n","    # 1. tokenize\n","    tokens = nltk.word_tokenize(text)\n","    # 2. check if stopword\n","    tokens = [w.lower() for w in tokens if not w in stopwords.words(\"english\")]\n","    return tokens\n","\n","def get_frame_tensor(i):\n","  frames = []\n","  last_valid_filename = \"\"\n","  for j in range(1, 30):\n","    filename = str(i) + \"_\" + str(j) + \".jpg\"\n","    if not os.path.isfile(frame_directory + folders[(int)(i/50)] + filename):\n","      filename = last_valid_filename\n","    if filename == \"\":\n","      print(str(i) + \"_\" + str(j) + \".jpg\")\n","    file = Image.open(frame_directory + folders[(int)(i/50)] + filename)\n","    file = frame_process(file)\n","    frames.append(file)\n","    last_valid_filename = filename\n","  frames = torch.stack(frames)\n","  return frames\n","\n","def get_spect_tensor(i):\n","  filename = str(i) + \".jpg\"\n","  file = Image.open(spect_directory + folders[(int)(i/50)] + filename)\n","  file = spect_process(file)\n","  return file\n","\n","dictionary = {\n","    'EMPTY': 1\n","}\n","\n","def get_text_tensor(i):\n","  text = df.columns[i]\n","  text = preprocess_text(text)\n","  liszt = []\n","  for i in range(len(text)):\n","    if text[i] in dictionary:\n","      liszt.append((int)(dictionary[text[i]]))\n","    else:\n","      size = len(dictionary) + 1\n","      dictionary[text[i]] = size\n","      liszt.append((int)(dictionary[text[i]]))\n","  return torch.IntTensor(liszt).to(device), len(text)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6175,"status":"ok","timestamp":1722273527329,"user":{"displayName":"William W.","userId":"17998644639780254164"},"user_tz":420},"id":"5BKtw9kMomkx"},"outputs":[],"source":["text_tensors = []\n","text_lengths = []\n","MXLEN = 0\n","\n","for i in range(300):\n","  tt, text_length = get_text_tensor(i)\n","  text_tensors.append(tt)\n","  text_lengths.append(text_length)\n","  MXLEN = max(MXLEN, (int)(tt.size(0)))\n","\n","text_tensors = torch.nn.utils.rnn.pad_sequence(text_tensors, batch_first = True)"]},{"cell_type":"code","source":["frame_tensors = []\n","spect_tensors = []\n","\n","for i in range(300):\n","  frame_tensors.append(get_frame_tensor(i))\n","  spect_tensors.append(get_spect_tensor(i))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"id":"2MMeB9fjM_be","executionInfo":{"status":"error","timestamp":1722276046684,"user_tz":420,"elapsed":2519370,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"outputId":"b9ed5a26-d195-44ef-b5c8-f7c4e29734e8"},"execution_count":8,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-4a08eeeacc61>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mframe_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_frame_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mspect_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_spect_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-bc81d8206d29>\u001b[0m in \u001b[0;36mget_frame_tensor\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_directory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"fTZ_O7s2ir9k"},"source":["# Training Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W0FN8r02YItL","executionInfo":{"status":"aborted","timestamp":1722276046685,"user_tz":420,"elapsed":7,"user":{"displayName":"William W.","userId":"17998644639780254164"}}},"outputs":[],"source":["model1 = CNN3d().to(device)\n","model2 = resnet18(pretrained = True).to(device) # output == 1000 neurons\n","model3 = LSTM_Classifier(vocab_size = len(dictionary) + 1,\n","                         embedding_dim = 100,\n","                         hidden_dim = 64,\n","                         output_dim = 6,\n","                         n_layers = 5,\n","                         bidirectional = True,\n","                         dropout = 0.5).to(device)\n","model4 = Smash().to(device)\n","\n","epochs = 10\n","\n","optimizer1 = optim.Adam(model1.parameters(), lr = 0.001)\n","optimizer2 = optim.Adam(model2.parameters(), lr = 0.01)\n","optimizer3 = optim.Adam(model3.parameters(), lr = 0.01)\n","optimizer4 = optim.Adam(model4.parameters(), lr = 0.01)\n","\n","loss_fn = nn.CrossEntropyLoss()\n","\n","tl = []\n","\n","def zerograd():\n","  optimizer1.zero_grad()\n","  optimizer2.zero_grad()\n","  optimizer3.zero_grad()\n","  optimizer4.zero_grad()\n","\n","def step():\n","  optimizer1.step()\n","  optimizer2.step()\n","  optimizer3.step()\n","  optimizer4.step()\n","\n","for i in range(epochs):\n","  model1.train()\n","  model2.train()\n","  model3.train()\n","  model4.train()\n","  train_loss = 0.00\n","  correct = 0.00\n","  total = 0.00\n","  for index, label in train_loader:\n","    index = index.cuda()\n","    label = label.cuda()\n","    text = text_tensors[index].to(device)\n","    if text_lengths[index] == 0:\n","      text = torch.IntTensor([dictionary['EMPTY']]).to(device)\n","      text = text.unsqueeze(0)\n","      text = text.unsqueeze(0)\n","      text_lengths[index] = 1\n","    spect = spect_tensors[index].to(device)\n","    frames = frame_tensors[index].to(device)\n","    frames.unsqueeze(0)\n","    frames = frames.transpose((1, 2))\n","    zerograd()\n","    y_frame = model1(frames).to(device)\n","    spect = spect.unsqueeze(0)\n","    assert spect.size(0) == 1\n","    y_spect = model2(spect).to(device)\n","    text = text.squeeze(1)\n","    y_text = model3(text, [text_lengths[index]]).to(device)\n","    input = torch.cat((y_frame, y_spect, y_text), dim=-1)\n","    y_pred = model4(input).to(device)\n","    labels = torch.full((1, 6,), 0.00).cuda()\n","    labels[0][label] = 1.00\n","    loss = loss_fn(y_pred, labels)\n","    loss.backward()\n","    step()\n","    train_loss += loss.item()/len(train_loader)\n","    prediction = y_pred.argmax(dim=1)\n","    correct += (prediction.eq(label).sum()).item()\n","    total += label.size(0)\n","  tl.append(train_loss)\n","  print(f\"Epoch: {i+1}/{epochs}, Training Loss: {train_loss:.4f}, Training Accuracy: {correct/total:.4f}\")"]},{"cell_type":"code","source":["#print(model2.weights.grad)\n","print(model3.lstm._parameters['weight_ih_l0'].grad)"],"metadata":{"id":"7brhahVRavhf","executionInfo":{"status":"aborted","timestamp":1722276046685,"user_tz":420,"elapsed":7,"user":{"displayName":"William W.","userId":"17998644639780254164"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"27uNcMn1yvxV"},"source":["# Validation Loop"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wr70yLwAyxrM","executionInfo":{"status":"aborted","timestamp":1722276046685,"user_tz":420,"elapsed":6,"user":{"displayName":"William W.","userId":"17998644639780254164"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyO0ZZwZvDzDujmd+mTnZRLV"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}