{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyMkhR46U048rYBnMUY81YDc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"JmRsruKiWoXZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gR49zxyfNNOZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722321855121,"user_tz":420,"elapsed":32208,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"outputId":"bfac4eda-28e9-4b26-bc4d-64f3882bbc8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Data manipulation and analysis\n","import pandas as pd\n","import numpy as np\n","\n","# Data visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Machine learning\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Deep learning with TensorFlow\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n","from tensorflow.keras.utils import to_categorical\n","\n","# Deep learning with PyTorch\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torchvision import models\n","\n","# Natural Language Processing (NLP)\n","import nltk\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","\n","# Miscellaneous\n","import os\n","import re\n","import time\n","import pickle\n","import cv2\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# Getting Audio Clips of CREMA-D"],"metadata":{"id":"T6sH2einjApj"}},{"cell_type":"code","source":["!pip install moviepy\n","from moviepy.editor import VideoFileClip"],"metadata":{"id":"fcK9jwfJi_zo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["directory = \"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/CREMA-D-Videos/\"\n","to_directory = \"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/CD-Audios/\"\n","\n","edict = { # this matches up with the indices for Ekman-6\n","    'ANG': 0,\n","    'DIS': 1,\n","    'FEA': 2,\n","    'HAP': 3,\n","    'SAD': 4,\n","}\n","\n","id = 250\n","files = [[], [], [], [], []]\n","\n","for file in os.listdir(directory):\n","  filename = os.fsdecode(file)\n","  emote = filename[9:12]\n","  if emote in edict:\n","    files[edict[emote]].append(filename)\n","\n","def write(read_path, write_path):\n","  clip = VideoFileClip(read_path)\n","  audio = clip.audio\n","  audio.write_audiofile(write_path)\n","  audio.close()\n","  clip.close()\n","\n","for i in range(5):\n","  for j in range(50):\n","    read_path = directory + files[i][j]\n","    write_path = to_directory + str(id) + \".mp3\"\n","    write(read_path, write_path)\n","    id += 1"],"metadata":{"id":"zXyX3jwfhTN8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Speech to Text"],"metadata":{"id":"A3Oah2cgoszs"}},{"cell_type":"code","source":["!pip install openai"],"metadata":{"id":"Z8sH_Ux4o5cF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from openai import OpenAI\n","key = \"sk-proj-WWodOl2OF1TJU7otVteuT3BlbkFJGeMH2FCoSxPCSXj5aNMt\"\n","client = OpenAI(api_key = key)\n","\n","def translated_text(filename):\n","  audio_file = open(filename, \"rb\")\n","  translation = client.audio.translations.create(\n","    model=\"whisper-1\",\n","    file=audio_file,\n","    temperature = 0.90\n","  )\n","  return translation.text\n","\n","texts = []\n","\n","for index in range(250, 500):\n","  texts.append(translated_text(to_directory + str(index) + \".mp3\"))"],"metadata":{"id":"pOuebYAho53F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import csv\n","\n","with open(\"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/CD_texts/transcripts.csv\", 'w') as myfile:\n","    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n","    wr.writerow(texts)"],"metadata":{"id":"5ujaP7Y5pkC5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Image to Spectrogram"],"metadata":{"id":"bdRpBSe8ppX8"}},{"cell_type":"code","source":[],"metadata":{"id":"7Ojk3YSqpsBO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Frame Cutting"],"metadata":{"id":"LzZlTMzvptgB"}},{"cell_type":"code","source":[],"metadata":{"id":"zx3o--j9pv85"},"execution_count":null,"outputs":[]}]}