{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyNQB/RLpWZJYCpA69QV9NYP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"9b317Ts4ueu9"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"EdIv1nEOucDK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722316802078,"user_tz":420,"elapsed":36315,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"outputId":"edea952a-3575-4215-adaf-ce2c7f04ff83"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Data manipulation and analysis\n","import pandas as pd\n","import numpy as np\n","\n","# Data visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Machine learning\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Deep learning with TensorFlow\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n","from tensorflow.keras.utils import to_categorical\n","\n","# Deep learning with PyTorch\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torchvision import models\n","from torchvision.models import resnet50, ResNet50_Weights\n","from torchvision.models import resnet18, ResNet18_Weights\n","\n","# Natural Language Processing (NLP)\n","import nltk\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","\n","# Miscellaneous\n","import os\n","import re\n","import time\n","import pickle\n","from PIL import Image\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","source":["# Dataset"],"metadata":{"id":"y0FuOD8x3ZAf"}},{"cell_type":"code","source":["nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","b_size = 1\n","\n","data = torch.load(\"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/ekman.pt\")\n","\n","data_loader = DataLoader(data, batch_size = b_size, shuffle = True, pin_memory = True, num_workers = 2)"],"metadata":{"id":"XrcvhRyM3Yd9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722316808569,"user_tz":420,"elapsed":4526,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"outputId":"c33ed384-732d-4c9e-cdf3-2b1046f31c9c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["import os.path\n","\n","frame_process = transforms.Compose([\n","    transforms.Resize((32, 32)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n","])\n","\n","def crop(image):\n","  return image.crop((80, 58, 577, 428))\n","\n","spect_process = transforms.Compose([\n","    transforms.Lambda(crop),\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","frame_directory = \"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/ekman6_split/\"\n","spect_directory = \"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/ekman6_spectro/\"\n","folders = [\"anger/\", \"disgust/\", \"fear/\", \"joy/\", \"sadness/\", \"surprise/\"]\n","df = pd.read_csv(\"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/ekman6_texts/en_transcripts.csv\")\n","\n","def preprocess_text(text: str) -> str:\n","    # remove links\n","    text = re.sub(r\"http\\S+\", \"\", text)\n","    # remove special chars and numbers\n","    text = re.sub(\"[^A-Za-z]+\", \" \", text)\n","    # remove stopwords\n","    # 1. tokenize\n","    tokens = nltk.word_tokenize(text)\n","    # 2. check if stopword\n","    tokens = [w.lower() for w in tokens if not w in stopwords.words(\"english\")]\n","    return tokens\n","\n","def get_frame_tensor(i):\n","  frames = []\n","  last_valid_filename = \"\"\n","  for j in range(1, 11):\n","    filename = str(i) + \"_\" + str(j) + \".jpg\"\n","    if not os.path.isfile(frame_directory + folders[(int)(i/50)] + filename):\n","      filename = last_valid_filename\n","    if filename == \"\":\n","      print(str(i) + \"_\" + str(j) + \".jpg\")\n","    file = Image.open(frame_directory + folders[(int)(i/50)] + filename)\n","    file = frame_process(file)\n","    frames.append(file)\n","    last_valid_filename = filename\n","  frames = torch.stack(frames)\n","  return frames\n","\n","def get_spect_tensor(i):\n","  filename = str(i) + \".jpg\"\n","  file = Image.open(spect_directory + folders[(int)(i/50)] + filename)\n","  file = spect_process(file)\n","  return file\n","\n","dictionary = {\n","    'EMPTY': 1 # EMPTY --> signal that the text is empty and contains nothing\n","}\n","\n","def get_text_tensor(i):\n","  text = df.columns[i]\n","  text = preprocess_text(text)\n","  liszt = [] # the processed version of the text\n","  for i in range(len(text)):\n","    if text[i] in dictionary:\n","      liszt.append((int)(dictionary[text[i]]))\n","    else:\n","      size = len(dictionary) + 1\n","      dictionary[text[i]] = size\n","      liszt.append((int)(dictionary[text[i]]))\n","  return torch.Tensor(liszt).to(device).to(torch.int64), len(text)"],"metadata":{"id":"bj-p8cPG34sM","executionInfo":{"status":"ok","timestamp":1722316813209,"user_tz":420,"elapsed":1573,"user":{"displayName":"William W.","userId":"17998644639780254164"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["text_tensors = []\n","text_lengths = []\n","MXLEN = 0\n","\n","num_input_videos = 300\n","\n","for i in range(num_input_videos):\n","  tt, text_length = get_text_tensor(i)\n","  text_tensors.append(tt)\n","  text_lengths.append(text_length)\n","  MXLEN = max(MXLEN, (int)(tt.size(0)))\n","\n","text_tensors = torch.nn.utils.rnn.pad_sequence(text_tensors, batch_first = True)"],"metadata":{"id":"y146cBc-35ow","executionInfo":{"status":"ok","timestamp":1722316822125,"user_tz":420,"elapsed":6295,"user":{"displayName":"William W.","userId":"17998644639780254164"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#frame_tensors = []\n","spect_tensors = []\n","\n","for i in range(300):\n","  #print(i)\n","  #frame_tensors.append(get_frame_tensor(i))\n","  spect_tensors.append(get_spect_tensor(i))"],"metadata":{"id":"6FOJlG4g38cA","executionInfo":{"status":"ok","timestamp":1722317032214,"user_tz":420,"elapsed":208135,"user":{"displayName":"William W.","userId":"17998644639780254164"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["ds = torch.load(\"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/frame.pt\")\n","print(ds.size())"],"metadata":{"id":"NSaCJxXc4HIj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722317037643,"user_tz":420,"elapsed":2662,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"outputId":"31a21b1a-35c5-450f-cc11-7866f55db752"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([300, 10, 3, 32, 32])\n"]}]},{"cell_type":"markdown","source":["# Evaluation Loop"],"metadata":{"id":"8oV2HZmR3aI_"}},{"cell_type":"code","source":["import __main__\n","setattr(__main__, \"Smash\", Smash)\n","model = torch.load(os.path.join(\"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/vmodel1.pt\",\"<path to pickle>\"), map_location=torch.device(\"cpu\"))\n","model.eval()\n","\n","predicts = []\n","corrects = []\n","mapping = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n","\n","index = 0\n","\n","with torch.no_grad():\n","  for indices, label in data_loader:\n","    indices = indices.cuda()\n","    label = label.cuda()\n","\n","    # getting the text for the index-th video\n","    text_batch = []\n","    for index in indices:\n","      text = text_tensors[index].to(device)\n","      # if the text ends up being nothing\n","      if text_lengths[index] == 0:\n","        text[0] = dictionary['EMPTY']\n","        # dimensionality voodoo\n","        text_lengths[index] = 1\n","      text_batch.append(text)\n","    text_batch = torch.stack(text_batch)\n","    text_batch = text_batch.squeeze(1)\n","\n","    # getting the spectrograms\n","    spect_batch = []\n","    for index in indices:\n","      spect = spect_tensors[index].to(device)\n","      spect.requires_grad = True\n","      spect_batch.append(spect)\n","    spect_batch = torch.stack(spect_batch)\n","\n","    # getting all of the frames\n","    frame_batch = []\n","    for index in indices:\n","      frames = ds[index.cpu()].to(device)\n","      frames = frames.squeeze(0)\n","      frame_batch.append(frames)\n","    frame_batch = torch.stack(frame_batch)\n","    frame_batch = torch.transpose(frame_batch, 1, 2)\n","\n","    # getting the text lengths\n","    textl = []\n","    for index in indices:\n","      textl.append(text_lengths[index])\n","\n","    # output of the final NN on the super-tensor\n","    y_pred = model(spect_batch, text_batch, textl, frame_batch).to(device)\n","\n","    prediction = y_pred.argmax(dim=1)\n","\n","    predicts.append(prediction.item())\n","    corrects.append(label.item())\n","\n","    if index < 5:\n","      print(index, mapping[prediction.item()])\n","\n","    index += 1\n","\n","confucian = metrics.confusion_matrix(corrects, predicts)\n","cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = mapping)\n"],"metadata":{"id":"wqG-5rv03ciW","colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"error","timestamp":1722317202049,"user_tz":420,"elapsed":1148,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"outputId":"79052ddc-e314-49ff-d5ec-4b24ce9b0dd7"},"execution_count":8,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Smash' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-656f9bc81823>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__main__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__main__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Smash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSmash\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/vmodel1.pt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"<path to pickle>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Smash' is not defined"]}]}]}