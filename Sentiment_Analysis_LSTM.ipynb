{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNRn5Rg00RV+8BozJLgVNJA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Implementing an LSTM to classify audio"],"metadata":{"id":"U72dBk0Tro7j"}},{"cell_type":"code","source":["!python --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gfJYQWk_zDJ6","executionInfo":{"status":"ok","timestamp":1722031355817,"user_tz":420,"elapsed":326,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"outputId":"b1786132-f1c2-4641-8ca0-e78e3b74411f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.12\n"]}]},{"cell_type":"code","source":["!pip install torchtext"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p-ugcXfg0WgQ","executionInfo":{"status":"ok","timestamp":1722031407711,"user_tz":420,"elapsed":51895,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"outputId":"21e2be4a-c769-408f-9d18-442f2188cadd"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.18.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.31.0)\n","Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.3.1+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.25.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (2024.6.1)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.3.0->torchtext)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.3.0->torchtext)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.3.0->torchtext)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.3.0->torchtext)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.3.0->torchtext)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.3.0->torchtext)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.3.0->torchtext)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.3.0->torchtext)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.3.0->torchtext)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.3.0->torchtext)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.3.0->torchtext)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext) (2.3.1)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.0->torchtext)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchtext) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.3.0->torchtext) (1.3.0)\n","Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2mPK6SHDrkao","executionInfo":{"status":"ok","timestamp":1722031426896,"user_tz":420,"elapsed":19188,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"outputId":"42e8c758-1d64-4011-8135-5092027be48d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x796acc752050>"]},"metadata":{},"execution_count":3}],"source":["import torch\n","import pandas as pd\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","\n","SEED = 42\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","torch.manual_seed(42)"]},{"cell_type":"code","source":["data = pd.read_csv(\"/content/drive/My Drive/Machine Learning/COSMOS/FINAL_PROJECT/DER/emot140.csv\")\n","data = data.drop('Unnamed: 0', axis = 1)\n","data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ISi1ASH3wzDN","executionInfo":{"status":"ok","timestamp":1722031433645,"user_tz":420,"elapsed":6753,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"outputId":"47c0bba1-82ef-4ccf-d76f-e86ddd02fc75"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   emote                                               text\n","0      0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n","1      0  is upset that he can't update his Facebook by ...\n","2      0  @Kenichan I dived many times for the ball. Man...\n","3      0    my whole body feels itchy and like its on fire \n","4      0  @nationwideclass no, it's not behaving at all...."],"text/html":["\n","  <div id=\"df-a23e9650-f4f8-4a6a-85d3-31f170293a58\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>emote</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>is upset that he can't update his Facebook by ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>@Kenichan I dived many times for the ball. Man...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>my whole body feels itchy and like its on fire</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>@nationwideclass no, it's not behaving at all....</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a23e9650-f4f8-4a6a-85d3-31f170293a58')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a23e9650-f4f8-4a6a-85d3-31f170293a58 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a23e9650-f4f8-4a6a-85d3-31f170293a58');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-71a89972-0774-4b88-9e04-5e39b62b7433\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71a89972-0774-4b88-9e04-5e39b62b7433')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-71a89972-0774-4b88-9e04-5e39b62b7433 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["import re\n","import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","\n","texties = []\n","labels = []\n","dictionary = {}\n","size = 0\n","\n","num_zeros = 0\n","num_twos = 0\n","num_fours = 0\n","\n","def preprocess_text(text: str) -> str:\n","    # remove links\n","    text = re.sub(r\"http\\S+\", \"\", text)\n","    # remove special chars and numbers\n","    text = re.sub(\"[^A-Za-z]+\", \" \", text)\n","    # remove stopwords\n","    # 1. tokenize\n","    tokens = nltk.word_tokenize(text)\n","    # 2. check if stopword\n","    tokens = [w.lower() for w in tokens if not w in stopwords.words(\"english\")]\n","    return tokens\n","\n","for index, row in data.iterrows():\n","  # checking if we can append to the end of the list\n","  coolio = False\n","  if (num_zeros == 50000 and num_twos == 50000 and num_fours == 50000):\n","    break\n","  if ((row['emote'] == 0 and num_zeros < 50000) or (row['emote'] == 2 and num_twos < 50000) or (row['emote'] == 4 and num_fours < 50000)):\n","    coolio = True\n","  if not coolio:\n","    continue\n","\n","  # processing the damn thing\n","  texts = preprocess_text(row['text'])\n","  words = []\n","  for i in range(len(texts)):\n","    if texts[i] in dictionary:\n","      words.append(dictionary[texts[i]])\n","    else:\n","      size += 1\n","      dictionary[texts[i]] = size\n","      words.append(size)\n","  if len(words) == 0:\n","    continue\n","\n","  # updating the counts\n","  num_zeros += (row['emote'] == 0)\n","  num_twos += (row['emote'] == 2)\n","  num_fours += (row['emote'] == 4)\n","\n","  # appends\n","  texties.append(torch.tensor(words, dtype = torch.int32))\n","  labels.append(torch.tensor([row['emote']], dtype = torch.int32))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SU2pvhZ83CdX","executionInfo":{"status":"ok","timestamp":1722035455949,"user_tz":420,"elapsed":235542,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"outputId":"bcd841c7-fbe0-4499-ea76-c46927404edd"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","Exception ignored in: <function SeekableUnicodeStreamReader.__del__ at 0x7969a35d2b00>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/nltk/data.py\", line 1160, in __del__\n","    if not self.closed:\n","  File \"/usr/local/lib/python3.10/dist-packages/nltk/data.py\", line 1180, in closed\n","    return self.stream.closed\n","AttributeError: 'SeekableUnicodeStreamReader' object has no attribute 'stream'\n"]}]},{"cell_type":"code","source":["text = torch.nn.utils.rnn.pad_sequence(texties, batch_first = True)\n","label = torch.stack(labels)\n","tdset = torch.utils.data.TensorDataset(text, label)"],"metadata":{"id":"ljaj3cVS8et-","executionInfo":{"status":"ok","timestamp":1722035461489,"user_tz":420,"elapsed":729,"user":{"displayName":"William W.","userId":"17998644639780254164"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["MXLEN = 0\n","for i in range(100000):\n","  MXLEN = max(MXLEN, texties[i].size(0))\n","print(MXLEN)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OEA4FJHhUpGT","executionInfo":{"status":"ok","timestamp":1722035793661,"user_tz":420,"elapsed":177,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"outputId":"9013d767-c973-4a61-ece3-ef71ae898835"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["36\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","class LSTM_Classifier(nn.Module):\n","  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n","    super(LSTM_Classifier, self).__init__()\n","    # Embedding layer converts integer sequences to vector sequences\n","    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","    # LSTM layer process the vector sequences\n","    self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers = n_layers, bidirectional = bidirectional, dropout = dropout, batch_first = True)\n","    #                     input           output                             bisexual?                      dropout_prob      whether or not batch_size comes first in the tensor.size()\n","    # Dense layer to predict\n","    self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","    # Prediction activation function\n","    self.sigmoid = nn.Sigmoid()\n","\n","  def forward(self, text, text_lengths):\n","    embedded = self.embedding(text) # embedded version\n","    # Thanks to packing, LSTM don't see padding tokens\n","    # and this makes our model better\n","    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, batch_first=True, enforce_sorted = False)\n","    packed_output, (hidden_state, cell_state) = self.lstm(packed_embedded)\n","    # Concatenating the final forward and backward hidden states\n","    hidden = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1)\n","    dense_outputs = self.fc(hidden)\n","    #Final activation function\n","    outputs = self.sigmoid(dense_outputs)\n","    return outputs\n"],"metadata":{"id":"5Ku_EqhB1BFd","executionInfo":{"status":"ok","timestamp":1722035807201,"user_tz":420,"elapsed":145,"user":{"displayName":"William W.","userId":"17998644639780254164"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","print(len(tdset))\n","train_len = (int)(0.900 * len(tdset))\n","train_dataset, test_dataset = torch.utils.data.random_split(tdset, [train_len, len(tdset) - train_len])\n","print(train_len, len(tdset) - train_len)\n","\n","b_size = 50\n","\n","train_loader = DataLoader(train_dataset, batch_size = b_size, shuffle = True, pin_memory = True, num_workers = 2)\n","test_loader = DataLoader(test_dataset, batch_size = b_size, shuffle = False, pin_memory = True, num_workers = 2)\n","print(len(train_dataset))\n","print(len(test_dataset))"],"metadata":{"id":"lA9w4k0k-Osg","executionInfo":{"status":"ok","timestamp":1722035808633,"user_tz":420,"elapsed":146,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"235b7bed-3489-456e-e02b-7f6798bf539e"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["100000\n","90000 10000\n","90000\n","10000\n"]}]},{"cell_type":"markdown","source":["# Training Loop"],"metadata":{"id":"D58V_1qB_gu1"}},{"cell_type":"code","source":["model = LSTM_Classifier(vocab_size = len(dictionary) + 1,\n","                        embedding_dim = 100,\n","                        hidden_dim = 64,\n","                        output_dim = 5,\n","                        n_layers = 5,\n","                        bidirectional = True,\n","                        dropout = 0.5).to(device)\n","optimizer = optim.Adam(model.parameters(), lr = 0.001)\n","loss_fn = nn.BCELoss().to(device)\n","epochs = 15\n","\n","for i in range(epochs):\n","  model.train()\n","  train_loss = 0.00\n","  correct = 0.00\n","  total = 0.00\n","  for tweet, emotion in train_loader:\n","    tweet = tweet.cuda()\n","    emotion = emotion.cuda()\n","    text_lengths = []\n","    for j in range(b_size):\n","      goddamn = False\n","      for k in range(MXLEN):\n","        if tweet[j][k] == 0:\n","          text_lengths.append(k)\n","          goddamn = True\n","          break\n","      if goddamn == False:\n","        text_lengths.append(MXLEN)\n","    emotion_ = torch.nn.functional.one_hot(emotion.to(torch.int64), 5).to(torch.float)\n","    emotion_ = emotion_.squeeze(1)\n","    optimizer.zero_grad()\n","    y_pred = model(tweet, text_lengths)\n","    loss = loss_fn(y_pred, emotion_)\n","    loss.backward()\n","    optimizer.step()\n","    train_loss += loss.item()/len(train_loader)\n","    prediction = y_pred.argmax(dim=1)\n","    emotion = emotion.squeeze(1)\n","    correct += prediction.eq(emotion).sum().item()\n","    total += emotion.size(0)\n","  print(correct, total)\n","  print(f\"Epoch: {i+1}/{epochs}, Training Loss: {train_loss:.4f}, Training Accuracy: {correct/total:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":738},"id":"CxNCNCKn_QA-","executionInfo":{"status":"error","timestamp":1722036415967,"user_tz":420,"elapsed":601463,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"outputId":"0c42b88a-35f8-448f-bc6c-c12b39a78326"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["45081.0 90000.0\n","Epoch: 1/15, Training Loss: 0.2814, Training Accuracy: 0.5009\n","61317.0 90000.0\n","Epoch: 2/15, Training Loss: 0.2328, Training Accuracy: 0.6813\n","70650.0 90000.0\n","Epoch: 3/15, Training Loss: 0.1843, Training Accuracy: 0.7850\n","74253.0 90000.0\n","Epoch: 4/15, Training Loss: 0.1581, Training Accuracy: 0.8250\n","77581.0 90000.0\n","Epoch: 5/15, Training Loss: 0.1319, Training Accuracy: 0.8620\n","80452.0 90000.0\n","Epoch: 6/15, Training Loss: 0.1057, Training Accuracy: 0.8939\n","82891.0 90000.0\n","Epoch: 7/15, Training Loss: 0.0826, Training Accuracy: 0.9210\n","84664.0 90000.0\n","Epoch: 8/15, Training Loss: 0.0646, Training Accuracy: 0.9407\n","85993.0 90000.0\n","Epoch: 9/15, Training Loss: 0.0503, Training Accuracy: 0.9555\n","86810.0 90000.0\n","Epoch: 10/15, Training Loss: 0.0409, Training Accuracy: 0.9646\n","87407.0 90000.0\n","Epoch: 11/15, Training Loss: 0.0343, Training Accuracy: 0.9712\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-03118ef3a34a>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# Validation Loop"],"metadata":{"id":"xjfbbiReBaG8"}},{"cell_type":"code","source":["model.eval()\n","val_loss = 0.00\n","correct = 0.00\n","total = 0.00\n","\n","for tweet, emotion in test_loader:\n","  tweet = tweet.cuda()\n","  emotion = emotion.cuda()\n","  text_lengths = []\n","  for j in range(b_size):\n","    goddamn = False\n","    for k in range(MXLEN):\n","      if tweet[j][k] == 0:\n","        text_lengths.append(k)\n","        goddamn = True\n","        break\n","    if goddamn == False:\n","      text_lengths.append(MXLEN)\n","  emotion_ = torch.nn.functional.one_hot(emotion.to(torch.int64), 5).to(torch.float)\n","  emotion_ = emotion_.squeeze(1)\n","  with torch.no_grad():\n","    y_pred = model(tweet, text_lengths)\n","  loss = loss_fn(y_pred, emotion_)\n","  val_loss += loss.item()/len(test_loader)\n","  emotion = emotion.squeeze(1)\n","  prediction = y_pred.argmax(dim=1)\n","  correct += prediction.eq(emotion).sum().item()\n","  #print(correct, total)\n","  total += emotion.size(0)\n","\n","print(f\"Validation Loss: {val_loss:.4f}\")\n","print(f\"Validation Accuracy: {correct/total:.4f}\")"],"metadata":{"id":"UwmMdxIPBZz4","executionInfo":{"status":"ok","timestamp":1722036444497,"user_tz":420,"elapsed":4627,"user":{"displayName":"William W.","userId":"17998644639780254164"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0adea106-04cf-475b-97c1-b8391edc03e8"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Loss: 0.4543\n","Validation Accuracy: 0.7302\n"]}]}]}